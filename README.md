# Ensemble Knowledge Distillation for Semantic Segmentation

## üéØ Project Overview

This project implements an **ensemble knowledge distillation** framework for semantic segmentation on desert terrain images. We use two powerful teacher models (DeepLabV3+ and SegFormer-B3) to train a lightweight student model (SegFormer-B1), achieving competitive performance with significantly fewer parameters.

---

## üìä Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        TRAINING PIPELINE                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Phase 1: Teacher Training
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DeepLabV3+          ‚îÇ      ‚îÇ  SegFormer-B3        ‚îÇ
‚îÇ  + ResNet50          ‚îÇ      ‚îÇ  (mit-b3)            ‚îÇ
‚îÇ  Backbone            ‚îÇ      ‚îÇ                      ‚îÇ
‚îÇ                      ‚îÇ      ‚îÇ                      ‚îÇ
‚îÇ  Parameters: ~40M    ‚îÇ      ‚îÇ  Parameters: ~45M    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                             ‚îÇ
           ‚îÇ Train on Dataset            ‚îÇ Train on Dataset
           ‚îÇ                             ‚îÇ
           ‚ñº                             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ deep_lab.pth ‚îÇ              ‚îÇ best_model.pth‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


Phase 2: Ensemble Knowledge Distillation
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ deep_lab.pth ‚îÇ              ‚îÇ best_model.pth‚îÇ
    ‚îÇ (frozen)     ‚îÇ              ‚îÇ (frozen)      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                              ‚îÇ
           ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ         ‚îÇ
           ‚ñº         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Ensemble Teacher       ‚îÇ
    ‚îÇ  (Weighted Average)     ‚îÇ
    ‚îÇ  Weight: [0.5, 0.5]     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚îÇ Soft Labels (Temperature Scaled)
                ‚îÇ
                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   SegFormer-B1          ‚îÇ
    ‚îÇ   (Student)             ‚îÇ
    ‚îÇ   Parameters: ~13.7M    ‚îÇ
    ‚îÇ                         ‚îÇ
    ‚îÇ   Learns from:          ‚îÇ
    ‚îÇ   ‚Ä¢ Teacher ensemble    ‚îÇ
    ‚îÇ   ‚Ä¢ Ground truth        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  best_student.pth       ‚îÇ
    ‚îÇ  (Lightweight Model)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üèóÔ∏è Model Architecture Details

### Teacher Models

#### 1. **DeepLabV3+ with ResNet50**
- **Architecture**: DeepLabV3+ with atrous spatial pyramid pooling (ASPP)
- **Backbone**: ResNet50 (pretrained on ImageNet)
- **Parameters**: ~40M
- **Strengths**: 
  - Excellent multi-scale feature extraction
  - Strong boundary detection
  - Robust to object scale variations

#### 2. **SegFormer-B3**
- **Architecture**: Transformer-based encoder with lightweight MLP decoder
- **Backbone**: Mix Transformer (MiT-B3)
- **Parameters**: ~45M
- **Strengths**:
  - Global context understanding
  - Efficient hierarchical features
  - Better at capturing long-range dependencies

### Student Model

#### **SegFormer-B1**
- **Architecture**: Smaller Mix Transformer encoder
- **Backbone**: MiT-B1
- **Parameters**: ~13.7M (3x smaller than teachers!)
- **Target**: Learn compressed knowledge from teacher ensemble

---

## üìÇ Dataset Structure

```
Offroad_Segmentation_Training_Dataset/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ Color_Images/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_0001.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_0002.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ Segmentation/
‚îÇ       ‚îú‚îÄ‚îÄ image_0001.png
‚îÇ       ‚îú‚îÄ‚îÄ image_0002.png
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ val/
    ‚îú‚îÄ‚îÄ Color_Images/
    ‚îî‚îÄ‚îÄ Segmentation/
```

### Class Labels (10 classes)
```python
0: Trees
1: Lush Bushes
2: Dry Grass
3: Dry Bushes
4: Ground Clutter
5: Flowers
6: Logs
7: Rocks
8: Landscape
9: Sky
```

---

## üîß Training Process

### Phase 1: Train Teacher Models

Both teacher models are trained independently on the full dataset.

**Training Configuration:**
- Image Size: 512√ó512
- Batch Size: 8-16
- Learning Rate: 6e-5
- Optimizer: AdamW
- Loss: Cross-Entropy with class weights
- Augmentation: Flip, rotate, color jitter

**Output Files:**
- `deep_lab.pth` - DeepLabV3+ checkpoint
- `best_model.pth` - SegFormer-B3 checkpoint

### Phase 2: Ensemble Knowledge Distillation

The student model learns from both teachers simultaneously.

#### Distillation Loss Formula

```
L_total = Œ± √ó L_soft + (1 - Œ±) √ó L_hard

where:
L_soft  = KL_divergence(student_logits/T, teacher_logits/T) √ó T¬≤
L_hard  = CrossEntropy(student_logits, ground_truth)

T = temperature (controls softness)
Œ± = distillation weight (balance between soft/hard loss)
```

#### Key Hyperparameters

```python
temperature = 2.0          # Temperature for softening distributions
alpha_start = 0.3          # Start with more hard loss
alpha_end = 0.7            # End with more soft loss (progressive)
teacher_weights = [0.5, 0.5]  # Equal ensemble weights
learning_rate = 6e-5
batch_size = 8
num_epochs = 50
```

#### Progressive Distillation

The distillation weight (Œ±) increases linearly during training:
- **Early epochs**: More focus on ground truth (Œ±=0.3)
- **Later epochs**: More focus on teacher knowledge (Œ±=0.7)

This helps the student first learn basic features, then refine with teacher guidance.

---

## üíª Code Structure

```
project/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ensemble_knowledge_distillation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ Main training notebook with:
‚îÇ       ‚îú‚îÄ‚îÄ Dataset loading
‚îÇ       ‚îú‚îÄ‚îÄ Teacher ensemble setup
‚îÇ       ‚îú‚îÄ‚îÄ Student model initialization
‚îÇ       ‚îú‚îÄ‚îÄ Distillation loss implementation
‚îÇ       ‚îî‚îÄ‚îÄ Training loop
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ deep_lab.pth          # DeepLabV3+ checkpoint
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth         # SegFormer-B3 checkpoint
‚îÇ
‚îî‚îÄ‚îÄ outputs/
    ‚îú‚îÄ‚îÄ best_student.pth       # Trained student model
    ‚îú‚îÄ‚îÄ training_curves.png    # Training visualization
    ‚îî‚îÄ‚îÄ checkpoints/           # Intermediate checkpoints
```

---

## üöÄ Usage

### 1. Prepare Your Data

Organize your dataset following the structure above:
```bash
/path/to/dataset/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ Color_Images/
‚îÇ   ‚îî‚îÄ‚îÄ Segmentation/
‚îî‚îÄ‚îÄ val/
    ‚îú‚îÄ‚îÄ Color_Images/
    ‚îî‚îÄ‚îÄ Segmentation/
```

### 2. Train Teacher Models (if not already trained)

```python
# Train DeepLabV3+
teacher_deeplab = DeepLabV3Plus(num_classes=10)
# ... train on dataset
torch.save({
    'model_state_dict': teacher_deeplab.state_dict()
}, 'deep_lab.pth')

# Train SegFormer-B3
teacher_segformer = SegformerForSemanticSegmentation.from_pretrained(
    "nvidia/mit-b3", num_labels=10
)
# ... train on dataset
torch.save({
    'model_state_dict': teacher_segformer.state_dict()
}, 'best_model.pth')
```

### 3. Run Ensemble Knowledge Distillation

```python
# Update paths in config
config.train_dir = "/path/to/train"
config.val_dir = "/path/to/val"
config.deeplab_checkpoint = "/path/to/deep_lab.pth"
config.segformer_checkpoint = "/path/to/best_model.pth"

# Run training
student_model, history = train_distillation()
```

### 4. Inference with Trained Student

```python
# Load student model
student = SegformerForSemanticSegmentation.from_pretrained(
    "nvidia/mit-b1", num_labels=10
)
checkpoint = torch.load('outputs/best_student.pth')
student.load_state_dict(checkpoint['model_state_dict'])
student.eval()

# Run inference
with torch.no_grad():
    outputs = student(image_tensor)
    predictions = outputs.logits.argmax(dim=1)
```

---

## üìà Results

### Model Comparison

| Model | Parameters | mIoU | Inference Speed |
|-------|-----------|------|-----------------|
| DeepLabV3+ (Teacher) | ~40M | 60% | ~30 FPS |
| SegFormer-B3 (Teacher) | ~45M | 65% | ~35 FPS |
| **SegFormer-B1 (Student)** | **~13.7M** | **65.55%** | **~80 FPS** |

### Advantages of Ensemble Distillation

‚úÖ **3x smaller model** with competitive performance  
‚úÖ **2-3x faster inference** - ideal for deployment  
‚úÖ **Better generalization** - learns from multiple teachers  
‚úÖ **Improved rare class performance** - teachers complement each other  

---

## üî¨ Technical Details

### Why Ensemble Teachers?

1. **Complementary Strengths**: 
   - DeepLabV3+ excels at fine boundaries
   - SegFormer captures global context
   - Ensemble combines both advantages

2. **Robustness**: 
   - Multiple teachers provide more stable soft labels
   - Reduces overfitting to single model biases

3. **Knowledge Diversity**:
   - Different architectures learn different features
   - Student benefits from richer supervision

### Key Implementation Details

#### 1. **Stable Loss Computation**
```python
# Clamp logits to prevent numerical overflow
student_logits = torch.clamp(student_logits / T, -10, 10)
teacher_logits = torch.clamp(teacher_logits / T, -10, 10)

# Clamp KL divergence to prevent explosion
soft_loss = torch.clamp(soft_loss, 0, 100)
```

#### 2. **Class Weight Balancing**
```python
# Compute weights from RAW masks (before augmentation)
class_weights = compute_class_weights_from_raw(dataset)

# Cap extreme weights to prevent instability
class_weights = np.clip(class_weights, 0.1, 10.0)
```

#### 3. **Teacher Output Alignment**
```python
# Interpolate SegFormer output to match input size
logits_sf = F.interpolate(
    segformer_logits, 
    size=(H, W), 
    mode='bilinear', 
    align_corners=False
)

# Ensemble: weighted average
ensemble = 0.5 * logits_sf + 0.5 * logits_dl
```

---

## üêõ Common Issues & Solutions

### Issue 1: Missing Classes in Weight Computation
**Problem**: Rare classes show 0 pixels  
**Cause**: Computing weights after augmentation destroys rare classes  
**Solution**: Use `get_raw_mask()` to read masks before augmentation

### Issue 2: Exploding Loss (>1000)
**Problem**: Training loss becomes extremely large  
**Cause**: Numerical instability in KL divergence  
**Solution**: Clamp logits and soft loss values

### Issue 3: Only Few Classes Have IoU
**Problem**: Validation shows IoU only for 2-3 classes  
**Cause**: Model collapsing to dominant classes  
**Solution**: 
- Use proper class weights
- Start with lower Œ± (more hard loss)
- Reduce temperature for sharper distributions

---

## üìö References

### Papers
1. **DeepLabV3+**: [Encoder-Decoder with Atrous Separable Convolution](https://arxiv.org/abs/1802.02611)
2. **SegFormer**: [Simple and Efficient Design for Semantic Segmentation](https://arxiv.org/abs/2105.15203)
3. **Knowledge Distillation**: [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)

### Code References
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Torchvision Models](https://pytorch.org/vision/stable/models.html)
- [Albumentations](https://albumentations.ai/)

---

## ü§ù Contributing

Contributions are welcome! Areas for improvement:
- [ ] Add more teacher models to ensemble
- [ ] Experiment with different ensemble weights
- [ ] Try feature-level distillation
- [ ] Implement attention-based distillation
- [ ] Add model quantization for edge deployment

---

## üìÑ License

This project is for educational purposes. Please cite the original papers if you use this code for research.

---

## üë• Authors

**Vedansh / Krackheads**  
Contact: vedanshtyagi999@gmail.com


## üìä Citation

If you use this code in your research, please cite:

```bibtex
@misc{ensemble_distillation_2024,
  author = {Vedansh Tyagi},
  title = {Ensemble Knowledge Distillation for Semantic Segmentation},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/VedanshTyagi/krackhack_offroad_segmentation_hackathon}
}
```

---

**Last Updated**: February 2026  
**Version**: 1.0.0
